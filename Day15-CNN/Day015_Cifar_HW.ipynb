{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(50000, 32, 32, 3)\n"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "WARNING: Logging before flag parsing goes to stderr.\nW0318 21:06:14.785120  9512 deprecation_wrapper.py:119] From C:\\Users\\Scherzando\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nW0318 21:06:14.803123  9512 deprecation_wrapper.py:119] From C:\\Users\\Scherzando\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nW0318 21:06:14.805123  9512 deprecation_wrapper.py:119] From C:\\Users\\Scherzando\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nW0318 21:06:14.826129  9512 deprecation_wrapper.py:119] From C:\\Users\\Scherzando\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nW0318 21:06:14.827129  9512 deprecation_wrapper.py:119] From C:\\Users\\Scherzando\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nW0318 21:06:15.683306  9512 deprecation_wrapper.py:119] From C:\\Users\\Scherzando\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n\nW0318 21:06:15.821337  9512 deprecation_wrapper.py:119] From C:\\Users\\Scherzando\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nW0318 21:06:15.905357  9512 deprecation.py:323] From C:\\Users\\Scherzando\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nEpoch 1/100\n50000/50000 [==============================] - 10s 192us/step - loss: 1.6641 - acc: 0.4526\nEpoch 2/100\n50000/50000 [==============================] - 9s 181us/step - loss: 1.0510 - acc: 0.6247\nEpoch 3/100\n50000/50000 [==============================] - 8s 167us/step - loss: 0.7949 - acc: 0.7180\nEpoch 4/100\n50000/50000 [==============================] - 8s 165us/step - loss: 0.6003 - acc: 0.7875\nEpoch 5/100\n50000/50000 [==============================] - 8s 163us/step - loss: 0.4203 - acc: 0.8549\nEpoch 6/100\n50000/50000 [==============================] - 8s 161us/step - loss: 0.3039 - acc: 0.8957\nEpoch 7/100\n50000/50000 [==============================] - 8s 164us/step - loss: 0.2167 - acc: 0.9271\nEpoch 8/100\n50000/50000 [==============================] - 9s 183us/step - loss: 0.1708 - acc: 0.9413\nEpoch 9/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.1411 - acc: 0.9518\nEpoch 10/100\n50000/50000 [==============================] - 10s 198us/step - loss: 0.1292 - acc: 0.9551\nEpoch 11/100\n50000/50000 [==============================] - 10s 191us/step - loss: 0.1070 - acc: 0.9632\nEpoch 12/100\n50000/50000 [==============================] - 9s 184us/step - loss: 0.0894 - acc: 0.9700\nEpoch 13/100\n50000/50000 [==============================] - 9s 180us/step - loss: 0.0902 - acc: 0.9704\nEpoch 14/100\n50000/50000 [==============================] - 11s 224us/step - loss: 0.0854 - acc: 0.9703\nEpoch 15/100\n50000/50000 [==============================] - 11s 215us/step - loss: 0.0748 - acc: 0.9757\nEpoch 16/100\n50000/50000 [==============================] - 10s 198us/step - loss: 0.0743 - acc: 0.9747\nEpoch 17/100\n50000/50000 [==============================] - 10s 195us/step - loss: 0.0672 - acc: 0.9766\nEpoch 18/100\n50000/50000 [==============================] - 10s 193us/step - loss: 0.0724 - acc: 0.9767\nEpoch 19/100\n50000/50000 [==============================] - 10s 193us/step - loss: 0.0587 - acc: 0.9808\nEpoch 20/100\n50000/50000 [==============================] - 10s 196us/step - loss: 0.0480 - acc: 0.9838\nEpoch 21/100\n50000/50000 [==============================] - 9s 180us/step - loss: 0.0506 - acc: 0.9834\nEpoch 22/100\n50000/50000 [==============================] - 10s 202us/step - loss: 0.0629 - acc: 0.9797\nEpoch 23/100\n50000/50000 [==============================] - 10s 198us/step - loss: 0.0470 - acc: 0.9852\nEpoch 24/100\n50000/50000 [==============================] - 10s 195us/step - loss: 0.0433 - acc: 0.9856\nEpoch 25/100\n50000/50000 [==============================] - 9s 185us/step - loss: 0.0471 - acc: 0.9853\nEpoch 26/100\n50000/50000 [==============================] - 9s 183us/step - loss: 0.0468 - acc: 0.9857\nEpoch 27/100\n50000/50000 [==============================] - 9s 183us/step - loss: 0.0403 - acc: 0.9871\nEpoch 28/100\n50000/50000 [==============================] - 9s 185us/step - loss: 0.0332 - acc: 0.9897\nEpoch 29/100\n50000/50000 [==============================] - 9s 188us/step - loss: 0.0463 - acc: 0.9853\nEpoch 30/100\n50000/50000 [==============================] - 9s 182us/step - loss: 0.0427 - acc: 0.9868\nEpoch 31/100\n50000/50000 [==============================] - 10s 190us/step - loss: 0.0360 - acc: 0.9895\nEpoch 32/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0382 - acc: 0.9885\nEpoch 33/100\n50000/50000 [==============================] - 10s 191us/step - loss: 0.0385 - acc: 0.9884\nEpoch 34/100\n50000/50000 [==============================] - 10s 191us/step - loss: 0.0314 - acc: 0.9903\nEpoch 35/100\n50000/50000 [==============================] - 10s 193us/step - loss: 0.0302 - acc: 0.9904\nEpoch 36/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0359 - acc: 0.9894\nEpoch 37/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0372 - acc: 0.9890\nEpoch 38/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0359 - acc: 0.9889\nEpoch 39/100\n50000/50000 [==============================] - 9s 186us/step - loss: 0.0340 - acc: 0.9899\nEpoch 40/100\n50000/50000 [==============================] - 9s 186us/step - loss: 0.0286 - acc: 0.9918\nEpoch 41/100\n50000/50000 [==============================] - 10s 190us/step - loss: 0.0215 - acc: 0.9932\nEpoch 42/100\n50000/50000 [==============================] - 9s 189us/step - loss: 0.0304 - acc: 0.9905\nEpoch 43/100\n50000/50000 [==============================] - 9s 186us/step - loss: 0.0233 - acc: 0.9929\nEpoch 44/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0392 - acc: 0.9878\nEpoch 45/100\n50000/50000 [==============================] - 9s 189us/step - loss: 0.0317 - acc: 0.9900\nEpoch 46/100\n50000/50000 [==============================] - 9s 190us/step - loss: 0.0238 - acc: 0.9925\nEpoch 47/100\n50000/50000 [==============================] - 9s 190us/step - loss: 0.0162 - acc: 0.9952\nEpoch 48/100\n50000/50000 [==============================] - 10s 192us/step - loss: 0.0135 - acc: 0.9956\nEpoch 49/100\n50000/50000 [==============================] - 9s 189us/step - loss: 0.0292 - acc: 0.9913\nEpoch 50/100\n50000/50000 [==============================] - 10s 193us/step - loss: 0.0336 - acc: 0.9905\nEpoch 51/100\n50000/50000 [==============================] - 9s 188us/step - loss: 0.0321 - acc: 0.9909\nEpoch 52/100\n50000/50000 [==============================] - 10s 194us/step - loss: 0.0287 - acc: 0.9914\nEpoch 53/100\n50000/50000 [==============================] - 9s 186us/step - loss: 0.0177 - acc: 0.9949\nEpoch 54/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0150 - acc: 0.9953\nEpoch 55/100\n50000/50000 [==============================] - 9s 189us/step - loss: 0.0236 - acc: 0.9926\nEpoch 56/100\n50000/50000 [==============================] - 9s 179us/step - loss: 0.0233 - acc: 0.9931\nEpoch 57/100\n50000/50000 [==============================] - 10s 191us/step - loss: 0.0192 - acc: 0.9938\nEpoch 58/100\n50000/50000 [==============================] - 9s 186us/step - loss: 0.0222 - acc: 0.9930\nEpoch 59/100\n50000/50000 [==============================] - 9s 184us/step - loss: 0.0141 - acc: 0.9958\nEpoch 60/100\n50000/50000 [==============================] - 9s 185us/step - loss: 0.0223 - acc: 0.9935\nEpoch 61/100\n50000/50000 [==============================] - 9s 186us/step - loss: 0.0265 - acc: 0.9916\nEpoch 62/100\n50000/50000 [==============================] - 10s 195us/step - loss: 0.0174 - acc: 0.9948\nEpoch 63/100\n50000/50000 [==============================] - 10s 191us/step - loss: 0.0304 - acc: 0.9916\nEpoch 64/100\n50000/50000 [==============================] - 10s 196us/step - loss: 0.0206 - acc: 0.9939\nEpoch 65/100\n50000/50000 [==============================] - 9s 185us/step - loss: 0.0144 - acc: 0.9955\nEpoch 66/100\n50000/50000 [==============================] - 10s 190us/step - loss: 0.0217 - acc: 0.9940\nEpoch 67/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0197 - acc: 0.9946\nEpoch 68/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0224 - acc: 0.9937\nEpoch 69/100\n50000/50000 [==============================] - 9s 189us/step - loss: 0.0150 - acc: 0.9952\nEpoch 70/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0181 - acc: 0.9944\nEpoch 71/100\n50000/50000 [==============================] - 10s 191us/step - loss: 0.0150 - acc: 0.9955\nEpoch 72/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0172 - acc: 0.9945\nEpoch 73/100\n50000/50000 [==============================] - 10s 192us/step - loss: 0.0164 - acc: 0.9954\nEpoch 74/100\n50000/50000 [==============================] - 10s 191us/step - loss: 0.0165 - acc: 0.9953\nEpoch 75/100\n50000/50000 [==============================] - 9s 188us/step - loss: 0.0189 - acc: 0.9947\nEpoch 76/100\n50000/50000 [==============================] - 10s 192us/step - loss: 0.0214 - acc: 0.9936\nEpoch 77/100\n50000/50000 [==============================] - 9s 188us/step - loss: 0.0154 - acc: 0.9956\nEpoch 78/100\n50000/50000 [==============================] - 9s 188us/step - loss: 0.0159 - acc: 0.9952\nEpoch 79/100\n50000/50000 [==============================] - 10s 190us/step - loss: 0.0102 - acc: 0.9968\nEpoch 80/100\n50000/50000 [==============================] - 9s 189us/step - loss: 0.0168 - acc: 0.9953\nEpoch 81/100\n50000/50000 [==============================] - 10s 193us/step - loss: 0.0195 - acc: 0.9942\nEpoch 82/100\n50000/50000 [==============================] - 9s 190us/step - loss: 0.0167 - acc: 0.9952\nEpoch 83/100\n50000/50000 [==============================] - 9s 189us/step - loss: 0.0133 - acc: 0.9960\nEpoch 84/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0115 - acc: 0.9965\nEpoch 85/100\n50000/50000 [==============================] - 9s 182us/step - loss: 0.0176 - acc: 0.9948\nEpoch 86/100\n50000/50000 [==============================] - 9s 183us/step - loss: 0.0118 - acc: 0.9967\nEpoch 87/100\n50000/50000 [==============================] - 9s 185us/step - loss: 0.0197 - acc: 0.9941\nEpoch 88/100\n50000/50000 [==============================] - 9s 177us/step - loss: 0.0210 - acc: 0.9937\nEpoch 89/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0138 - acc: 0.9960\nEpoch 90/100\n50000/50000 [==============================] - 9s 188us/step - loss: 0.0074 - acc: 0.9977\nEpoch 91/100\n50000/50000 [==============================] - 9s 185us/step - loss: 0.0099 - acc: 0.9969\nEpoch 92/100\n50000/50000 [==============================] - 9s 186us/step - loss: 0.0193 - acc: 0.9943\nEpoch 93/100\n50000/50000 [==============================] - 9s 187us/step - loss: 0.0163 - acc: 0.9951\nEpoch 94/100\n50000/50000 [==============================] - 9s 184us/step - loss: 0.0137 - acc: 0.9959\nEpoch 95/100\n50000/50000 [==============================] - 9s 186us/step - loss: 0.0110 - acc: 0.9970\nEpoch 96/100\n50000/50000 [==============================] - 9s 190us/step - loss: 0.0205 - acc: 0.9946\nEpoch 97/100\n50000/50000 [==============================] - 9s 189us/step - loss: 0.0116 - acc: 0.9967\nEpoch 98/100\n50000/50000 [==============================] - 9s 185us/step - loss: 0.0065 - acc: 0.9982\nEpoch 99/100\n50000/50000 [==============================] - 10s 190us/step - loss: 0.0128 - acc: 0.9964\nEpoch 100/100\n50000/50000 [==============================] - 10s 193us/step - loss: 0.0135 - acc: 0.9964\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x25c88465278>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=(32,32,3)\n",
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same', input_shape=input_shape, activation='relu'))#32,3,3,input_shape=(32,32,activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(100, activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    " \n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[8.3151863e-06, 1.7720941e-14, 3.1105816e-01, 6.8852711e-01,\n        3.5106356e-04, 1.5979352e-12, 3.6140452e-06, 5.3288381e-14,\n        5.1822182e-05, 7.8448221e-18]], dtype=float32)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}